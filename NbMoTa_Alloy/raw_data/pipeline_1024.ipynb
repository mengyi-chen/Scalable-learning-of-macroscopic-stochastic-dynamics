{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "sys.path.append('../')\n",
    "import re\n",
    "import torch\n",
    "from utils.utils import *\n",
    "from tqdm import tqdm\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283553b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    match = re.search(r'output_(\\d+)\\.npy', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403448f4",
   "metadata": {},
   "source": [
    "#  Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_atoms = 1024\n",
    "output_dir_short = '../data/output_atoms_1024_steps_2000000'\n",
    "# output_dir_long = '../data/output_atoms_1024_steps_20000000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d28930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(output_dir):\n",
    "    for folder in tqdm(os.listdir(output_dir)):\n",
    "        T = int(folder.split('_')[1])\n",
    "        folder_path = os.path.join(output_dir, folder)\n",
    "        log_path = os.path.join(folder_path, 'chemical_order.csv')\n",
    "        df = pd.read_csv(log_path)\n",
    "        \n",
    "        # ========= macroscopic data =========\n",
    "        macro_val = np.array([\n",
    "            df['delta_NbNb'].values,\n",
    "            df['delta_NbMo'].values,\n",
    "            df['delta_NbTa'].values,\n",
    "            df['delta_MoMo'].values,\n",
    "            df['delta_MoTa'].values,\n",
    "            df['delta_TaTa'].values\n",
    "        ]).T\n",
    "\n",
    "        # ========= T,steps,time data =========\n",
    "        time_path = os.path.join(folder_path, 'log.csv')\n",
    "        df_time = pd.read_csv(time_path)\n",
    "        time = df_time['time'].values\n",
    "        time = np.insert(time, 0, 0.0)  # Insert initial time step\n",
    "        T_state = np.ones(macro_val.shape[0], dtype=np.int32) * int(T)\n",
    "        step = df['step'].values\n",
    "\n",
    "        config_path = os.path.join(folder_path, 'config_data')\n",
    "        file_path = [f for f in os.listdir(config_path) if f.endswith('.npy')]\n",
    "        file_path = sorted(file_path, key=extract_number)\n",
    "        \n",
    "        # ========= microscopic data =========\n",
    "        # micro_val = []\n",
    "        # for file in file_path:\n",
    "        #     file_full_path = os.path.join(config_path, file)\n",
    "        #     grid = np.load(file_full_path)\n",
    "        #     micro_val.append(grid)\n",
    "        # micro_val = np.array(micro_val)\n",
    "\n",
    "        # ========= partial macroscopic data =========\n",
    "        # idx_partial = np.random.randint(0, 8, size=(macro_val.shape[0]-1,))\n",
    "        # initial_grid = micro_val[0]\n",
    "        # z0_partial = []\n",
    "        # z1_partial = []\n",
    "        # for j in range(idx_partial.shape[0]):\n",
    "        #     idx = idx_partial[j]\n",
    "        #     partial_grid_0 = micro_val[j].reshape(2, 8, 2, 8, 2, 8).transpose(0, 2, 4, 1, 3, 5).reshape(-1, 16, 16, 16)[idx]\n",
    "        #     partial_grid_1 = micro_val[j+1].reshape(2, 8, 2, 8, 2, 8).transpose(0, 2, 4, 1, 3, 5).reshape(-1, 16, 16, 16)[idx]\n",
    "\n",
    "        #     order_0 = cal_local_chemical_order(initial_grid, partial_grid_0)\n",
    "        #     order_1 = cal_local_chemical_order(initial_grid, partial_grid_1)\n",
    "        #     z0_partial.append(order_0)\n",
    "        #     z1_partial.append(order_1)\n",
    "\n",
    "        # z0_partial = np.array(z0_partial)\n",
    "        # z1_partial = np.array(z1_partial)\n",
    "        # macro_val_partial = macro_val[:-1] + (z1_partial - z0_partial)\n",
    "\n",
    "\n",
    "        # ========= save data =========\n",
    "        # np.save(os.path.join(folder_path, 'micro_val.npy'), micro_val)\n",
    "        np.save(os.path.join(folder_path, 'macro_val.npy'), macro_val)\n",
    "        np.save(os.path.join(folder_path, 'time.npy'), time)\n",
    "        np.save(os.path.join(folder_path, 'T_state.npy'), T_state)\n",
    "        np.save(os.path.join(folder_path, 'step.npy'), step)\n",
    "        # np.save(os.path.join(folder_path, 'macro_val_partial.npy'), macro_val_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4969272",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(output_dir_short)\n",
    "# preprocess(output_dir_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88098cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "micro_state = [] \n",
    "macro_state = []\n",
    "# macro_state_partial = []\n",
    "T_state = []\n",
    "time_state = []\n",
    "step_state = []\n",
    "\n",
    "# for output_dir in [output_dir_short, output_dir_long]:\n",
    "for output_dir in [output_dir_short]:\n",
    "# for output_dir in [output_dir_long]:\n",
    "    for folder in tqdm(os.listdir(output_dir)):\n",
    "        T = int(folder.split('_')[1])\n",
    "        folder_path = os.path.join(output_dir, folder)\n",
    "\n",
    "        micro_state.append(np.load(os.path.join(folder_path, 'micro_val.npy')))\n",
    "        macro_state.append(np.load(os.path.join(folder_path, 'macro_val.npy')))\n",
    "        # macro_state_partial.append(np.load(os.path.join(folder_path, 'macro_val_partial.npy')))\n",
    "        time_state.append(np.load(os.path.join(folder_path, 'time.npy')))\n",
    "        T_state.append(np.load(os.path.join(folder_path, 'T_state.npy')))\n",
    "        step_state.append(np.load(os.path.join(folder_path, 'step.npy')))\n",
    "\n",
    "\n",
    "micro_state = np.stack(micro_state, axis=0)\n",
    "macro_state = np.stack(macro_state, axis=0)\n",
    "# macro_state_partial = np.stack(macro_state_partial, axis=0)\n",
    "time_state = np.stack(time_state, axis=0)\n",
    "T_state = np.stack(T_state, axis=0)\n",
    "step_state = np.stack(step_state, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro_state.shape, \n",
    "macro_state.shape, T_state.shape, time_state.shape, step_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2133d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(T_state[:, 0]==2000)[0]\n",
    "time_state[idx, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d70678",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 800\n",
    "indices = np.where(T_state[:, 0] == T)[0]\n",
    "fig = plt.figure(figsize=(40, 6))\n",
    "for i in range(6):\n",
    "    axes = fig.add_subplot(1, 6, i+1)\n",
    "    for j in indices:\n",
    "        axes.plot(time_state[j], macro_state[j, :, i])\n",
    "        # axes.plot(macro_state[j, :, i])\n",
    "    axes.set_xlabel('Step')\n",
    "    axes.set_ylabel(f'Delta_{i}')\n",
    "    axes.hlines(0, 0, np.max(time_state[indices]), colors='black', linestyles='dashed', linewidth=1)\n",
    "    axes.set_ylim(-3.5, 3.5)\n",
    "    # plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.grid()\n",
    "plt.title(f'T = {T} K')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804622d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time = {}\n",
    "T_unique = np.unique(T_state[:, 0])\n",
    "for T in T_unique:\n",
    "    idx = np.where(T_state[:, 0] == T)[0]\n",
    "    steps = np.unique(step_state[idx, -1])\n",
    "    final_time[T.item()] = time_state[idx, -1].max().item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4271f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.array(list(final_time.keys()), dtype=float)      # e.g. [200,300,…]\n",
    "t = np.array(list(final_time.values()), dtype=float)    # corresponding final times\n",
    "\n",
    "# 2) prepare for linear fit:  y = ln t, x = 1/T\n",
    "x_high = 1.0 / T[9:]\n",
    "y_high = np.log(t[9:])\n",
    "\n",
    "x_med = 1.0 / T[4:9]\n",
    "y_med = np.log(t[4:9])\n",
    "\n",
    "x_low = 1.0 / T[:4]\n",
    "y_low = np.log(t[:4])\n",
    "\n",
    "# 3) do a 1st‐order polyfit: y ≈ m*x + b\n",
    "m_high, b_high = np.polyfit(x_high, y_high, 1)\n",
    "A_high = np.exp(b_high)                # prefactor\n",
    "Ea_over_kB_high = m_high               # slope = Eₐ/k_B\n",
    "\n",
    "print(f\"Arrhenius fit for high temperature: t = {A_high:.3e} · exp({Ea_over_kB_high:.1f}/T)\")\n",
    "\n",
    "m_med, b_med = np.polyfit(x_med, y_med, 1)\n",
    "A_med = np.exp(b_med)                # prefactor\n",
    "Ea_over_kB_med = m_med               # slope = Eₐ/k_B\n",
    "print(f\"Arrhenius fit for medium temperature: t = {A_med:.3e} · exp({Ea_over_kB_med:.1f}/T)\")\n",
    "\n",
    "m_low, b_low = np.polyfit(x_low, y_low, 1)\n",
    "A_low = np.exp(b_low)                # prefactor\n",
    "Ea_over_kB_low = m_low               # slope = Eₐ/k_B\n",
    "print(f\"Arrhenius fit for low temperature: t = {A_low:.3e} · exp({Ea_over_kB_low:.1f}/T)\")\n",
    "\n",
    "\n",
    "# 4) compute fitted curve\n",
    "t_fit_high = A_high * np.exp(Ea_over_kB_high / T[9:])\n",
    "t_fit_med = A_med * np.exp(Ea_over_kB_med / T[4:9])\n",
    "t_fit_low = A_low * np.exp(Ea_over_kB_low / T[:4])\n",
    "\n",
    "# 5) plot data & fit\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(T, t, label=\"data\", color=\"C0\")\n",
    "plt.plot(T[9:], t_fit_high, label=\"Arrhenius fit (high T)\", color=\"C1\")\n",
    "plt.plot(T[4:9], t_fit_med, label=\"Arrhenius fit (medium T)\", color=\"C2\")\n",
    "plt.plot(T[:4], t_fit_low, label=\"Arrhenius fit (low T)\", color=\"C3\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Temperature (K)\")\n",
    "plt.ylabel(\"Final time (ps)\")\n",
    "plt.title(\"Arrhenius fit of final time\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191bf691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx, val_idx = train_test_split(np.arange(macro_state.shape[0]), test_size=0.1)\n",
    "# train_idx.shape, val_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_function(T):\n",
    "    # Parameters for different temperature ranges\n",
    "    # High temperature (>= 1400K)\n",
    "    A_high = 3.946e-08\n",
    "    Ea_over_kB_high = 18036.1\n",
    "\n",
    "    # A_med = 1.877e-07\n",
    "    A_med = 5.316e-07\n",
    "    # Ea_over_kB_med = 19477.0  \n",
    "    Ea_over_kB_med = 15650.0\n",
    "\n",
    "    # Low temperature (<= 600 k)\n",
    "    # A_low = 7.512e-06\n",
    "    A_low = 1.847e-08\n",
    "    # Ea_over_kB_low = 15030.2\n",
    "    Ea_over_kB_low = 16478.3\n",
    "\n",
    "    # Create boolean masks for temperature ranges\n",
    "    high_temp_mask = T >= 1400\n",
    "    med_temp_mask = (T <= 1200) & (T > 600)\n",
    "    low_temp_mask = T <= 600 \n",
    "    \n",
    "    # Initialize result array\n",
    "    result = np.zeros_like(T, dtype=float)\n",
    "    \n",
    "    # Calculate scaling for high temperatures\n",
    "    if np.any(high_temp_mask):\n",
    "        result[high_temp_mask] = np.exp(-np.log(A_high) - Ea_over_kB_high/T[high_temp_mask])\n",
    "    \n",
    "    if np.any(med_temp_mask):\n",
    "        result[med_temp_mask] = np.exp(-np.log(A_med) - Ea_over_kB_med/T[med_temp_mask])\n",
    "    \n",
    "    # Calculate scaling for low temperatures\n",
    "    if np.any(low_temp_mask):\n",
    "        result[low_temp_mask] = np.exp(-np.log(A_low) - Ea_over_kB_low/T[low_temp_mask])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2f1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_value = scale_function(T_state)\n",
    "time_state_scaled = time_state * scale_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d28018",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time_scaled = {}\n",
    "for T in T_unique:\n",
    "    idx = np.where(T_state[:, 0] == T)[0]\n",
    "    final_time_scaled[T.item()] = time_state_scaled[idx, -1].max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb04b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(final_time_scaled.keys(), final_time_scaled.values(), label=\"data\", color=\"C0\")\n",
    "plt.xlabel(\"Temperature (K)\")\n",
    "plt.ylabel(\"Final time (ps)\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12270b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_state = torch.tensor(macro_state, dtype=torch.float32)\n",
    "# macro_state_partial = torch.tensor(macro_state_partial, dtype=torch.float32)\n",
    "T_state = torch.tensor(T_state, dtype=torch.int32)\n",
    "time_state = torch.tensor(time_state, dtype=torch.float32)\n",
    "time_state_scaled = torch.tensor(time_state_scaled, dtype=torch.float32)\n",
    "step_state = torch.tensor(step_state, dtype=torch.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b219bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(np.arange(macro_state.shape[0]), test_size=0.2)\n",
    "train_idx.shape, val_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683218b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T_state[:, :-1], time_state_scaled[:, 1:] - time_state_scaled[:, :-1], 'go', alpha=1, markersize=0.05)\n",
    "# plt.plot(final_time_scaled.keys(), mean_dt, 'ro', markersize=3)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676451c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "save_dir = f'../data/atoms_{N_atoms}'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# ========= save trainingdata =========\n",
    "# torch.save(micro_state[train_idx], f'{save_dir}/micro_state.pt')\n",
    "torch.save(macro_state[train_idx], f'{save_dir}/macro_state.pt')\n",
    "torch.save(T_state[train_idx], f'{save_dir}/T_state.pt')\n",
    "torch.save(time_state[train_idx], f'{save_dir}/time_state.pt')\n",
    "torch.save(time_state_scaled[train_idx], f'{save_dir}/time_state_scaled.pt')\n",
    "\n",
    " # ========= save partial data =========\n",
    "# save the partial macro state and idx_partial\n",
    "# torch.save(idx_partial[train_idx], f'../data/atoms_{N_atoms}/idx_partial.pt')\n",
    "# torch.save(macro_state_partial[train_idx], f'../data/atoms_{N_atoms}/macro_state_partial.pt')\n",
    "\n",
    "# ========= save validation data =========\n",
    "# torch.save(micro_state[val_idx], f'{save_dir}/micro_state_val.pt')\n",
    "torch.save(macro_state[val_idx], f'{save_dir}/macro_state_val.pt')\n",
    "torch.save(T_state[val_idx], f'{save_dir}/T_state_val.pt')\n",
    "torch.save(time_state[val_idx], f'{save_dir}/time_state_val.pt')\n",
    "torch.save(time_state_scaled[val_idx], f'{save_dir}/time_state_scaled_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99da9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
