{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "sys.path.append('../')\n",
    "import re\n",
    "import torch\n",
    "from utils.utils import * \n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    match = re.search(r'output_(\\d+)\\.npy', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403448f4",
   "metadata": {},
   "source": [
    "#  Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272923c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_atoms = 8192\n",
    "output_dir_short = '../data/output_atoms_8192_steps_2000000'\n",
    "# output_dir_long = '../data/output_atoms_8192_steps_2000000_near_equilibrium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d194ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(output_dir):\n",
    "    for folder in tqdm(os.listdir(output_dir)):\n",
    "        T = int(folder.split('_')[1])\n",
    "        folder_path = os.path.join(output_dir, folder)\n",
    "        log_path = os.path.join(folder_path, 'chemical_order.csv')\n",
    "        df = pd.read_csv(log_path)\n",
    "        \n",
    "        # ========= macroscopic data =========\n",
    "        macro_val = np.array([\n",
    "            df['delta_NbNb'].values,\n",
    "            df['delta_NbMo'].values,\n",
    "            df['delta_NbTa'].values,\n",
    "            df['delta_MoMo'].values,\n",
    "            df['delta_MoTa'].values,\n",
    "            df['delta_TaTa'].values\n",
    "        ]).T\n",
    "\n",
    "        # ========= T,steps,time data =========\n",
    "        time_path = os.path.join(folder_path, 'log.csv')\n",
    "        df_time = pd.read_csv(time_path)\n",
    "        time = df_time['time'].values\n",
    "        time = np.insert(time, 0, 0.0)  # Insert initial time step\n",
    "        T_state = np.ones(macro_val.shape[0], dtype=np.int32) * int(T)\n",
    "        step = df['step'].values\n",
    "\n",
    "        config_path = os.path.join(folder_path, 'config_data')\n",
    "        file_path = [f for f in os.listdir(config_path) if f.endswith('.npy')]\n",
    "        file_path = sorted(file_path, key=extract_number)\n",
    "        \n",
    "        # ========= microscopic data =========\n",
    "        # micro_val = []\n",
    "        # for file in file_path:\n",
    "        #     file_full_path = os.path.join(config_path, file)\n",
    "        #     grid = np.load(file_full_path)\n",
    "        #     micro_val.append(grid)\n",
    "        # micro_val = np.array(micro_val)\n",
    "\n",
    "        # ========= partial macroscopic data =========\n",
    "        # idx_partial = np.random.randint(0, 8, size=(macro_val.shape[0]-1,))\n",
    "        # z0_partial = []\n",
    "        # z1_partial = []\n",
    "        # for j in range(idx_partial.shape[0]):\n",
    "        #     idx = idx_partial[j]\n",
    "        #     partial_grid_0 = micro_val[j].reshape(2, 16, 2, 16, 2, 16).transpose(0, 2, 4, 1, 3, 5).reshape(-1, 16, 16, 16)[idx]\n",
    "        #     partial_grid_1 = micro_val[j+1].reshape(2, 16, 2, 16, 2, 16).transpose(0, 2, 4, 1, 3, 5).reshape(-1, 16, 16, 16)[idx]\n",
    "\n",
    "        #     order_0 = cal_local_chemical_order(partial_grid_0)\n",
    "        #     order_1 = cal_local_chemical_order(partial_grid_1)\n",
    "        #     z0_partial.append(order_0)\n",
    "        #     z1_partial.append(order_1)\n",
    "\n",
    "        # z0_partial = np.array(z0_partial)\n",
    "        # z1_partial = np.array(z1_partial)\n",
    "        # macro_val_partial = macro_val[:-1] + (z1_partial - z0_partial)\n",
    "\n",
    "\n",
    "        # ========= save data =========\n",
    "        # np.save(os.path.join(folder_path, 'micro_val.npy'), micro_val)\n",
    "        np.save(os.path.join(folder_path, 'macro_val.npy'), macro_val)\n",
    "        np.save(os.path.join(folder_path, 'time.npy'), time)\n",
    "        np.save(os.path.join(folder_path, 'T_state.npy'), T_state)\n",
    "        np.save(os.path.join(folder_path, 'step.npy'), step)\n",
    "        # np.save(os.path.join(folder_path, 'macro_val_partial.npy'), macro_val_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074b22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(output_dir_short)\n",
    "# preprocess(output_dir_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df62937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro_state = [] \n",
    "macro_state = []\n",
    "macro_state_partial = []\n",
    "T_state = []\n",
    "time_state = []\n",
    "step_state = []\n",
    "\n",
    "# for output_dir in [output_dir_short, output_dir_long]:\n",
    "for output_dir in [output_dir_short]:\n",
    "    for folder in tqdm(os.listdir(output_dir)):\n",
    "        T = int(folder.split('_')[1])\n",
    "        folder_path = os.path.join(output_dir, folder)\n",
    "\n",
    "        # micro_state.append(np.load(os.path.join(folder_path, 'micro_val.npy')))\n",
    "        macro_state.append(np.load(os.path.join(folder_path, 'macro_val.npy')))\n",
    "        macro_state_partial.append(np.load(os.path.join(folder_path, 'macro_val_partial.npy')))\n",
    "        time_state.append(np.load(os.path.join(folder_path, 'time.npy')))\n",
    "        T_state.append(np.load(os.path.join(folder_path, 'T_state.npy')))\n",
    "        step_state.append(np.load(os.path.join(folder_path, 'step.npy')))\n",
    "\n",
    "\n",
    "# micro_state = np.stack(micro_state, axis=0)\n",
    "macro_state = np.stack(macro_state, axis=0)\n",
    "macro_state_partial = np.stack(macro_state_partial, axis=0)\n",
    "time_state = np.stack(time_state, axis=0)\n",
    "T_state = np.stack(T_state, axis=0)\n",
    "step_state = np.stack(step_state, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b150b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2000\n",
    "indices = np.where(T_state[:, 0] == T)[0]\n",
    "fig = plt.figure(figsize=(40, 6))\n",
    "for i in range(6):\n",
    "    axes = fig.add_subplot(1, 6, i+1)\n",
    "    for j in indices:\n",
    "        axes.plot(time_state[j], macro_state[j, :, i])\n",
    "    axes.set_xlabel('Step')\n",
    "    axes.set_ylabel(f'Delta_{i}')\n",
    "    axes.hlines(0, 0, np.max(time_state[indices]), colors='black', linestyles='dashed', linewidth=1)\n",
    "    axes.set_ylim(-3.5, 3.5)\n",
    "plt.title(f'T = {T} K')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a8950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2000\n",
    "indices = np.where(T_state[:, 0] == T)[0]\n",
    "fig = plt.figure(figsize=(40, 6))\n",
    "for i in range(6):\n",
    "    axes = fig.add_subplot(1, 6, i+1)\n",
    "    for j in indices:\n",
    "        axes.plot(time_state[j, :-1], macro_state_partial[j, :, i])\n",
    "    axes.set_xlabel('Step')\n",
    "    axes.set_ylabel(f'Delta_{i}')\n",
    "    axes.hlines(0, 0, np.max(time_state[j]), colors='black', linestyles='dashed', linewidth=1)\n",
    "    axes.set_ylim(-3.5, 3.5)\n",
    "plt.title(f'T = {T} K')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661107b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time = {}\n",
    "T_unique = np.unique(T_state[:, 0])\n",
    "for T in T_unique:\n",
    "    idx = np.where(T_state[:, 0] == T)[0]\n",
    "    steps = np.unique(step_state[idx, -1])\n",
    "    final_time[T.item()] = time_state[idx, -1].max().item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a10097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.array(list(final_time.keys()), dtype=float)      # e.g. [200,300,…]\n",
    "t = np.array(list(final_time.values()), dtype=float)    # corresponding final times\n",
    "\n",
    "# 2) prepare for linear fit:  y = ln t, x = 1/T\n",
    "# x_high = 1.0 / T[9:]\n",
    "# y_high = np.log(t[9:])\n",
    "\n",
    "# x_low = 1.0 / T[:9]\n",
    "# y_low = np.log(t[:9])\n",
    "\n",
    "x = 1.0 / T\n",
    "y = np.log(t)\n",
    "\n",
    "# 3) do a 1st‐order polyfit: y ≈ m*x + b\n",
    "# m_high, b_high = np.polyfit(x_high, y_high, 1)\n",
    "# A_high = np.exp(b_high)                # prefactor\n",
    "# Ea_over_kB_high = m_high               # slope = Eₐ/k_B\n",
    "\n",
    "# print(f\"Arrhenius fit for high temperature: t = {A_high:.3e} · exp({Ea_over_kB_high:.1f}/T)\")\n",
    "\n",
    "# m_low, b_low = np.polyfit(x_low, y_low, 1)\n",
    "# A_low = np.exp(b_low)                # prefactor\n",
    "# Ea_over_kB_low = m_low               # slope = Eₐ/k_B\n",
    "# print(f\"Arrhenius fit for low temperature: t = {A_low:.3e} · exp({Ea_over_kB_low:.1f}/T)\")\n",
    "\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "A = np.exp(b)                # prefactor\n",
    "Ea_over_kB = m               # slope = Eₐ/k_B\n",
    "print(f\"Overall Arrhenius fit: t = {A:.3e} · exp({Ea_over_kB:.1f}/T)\")  \n",
    "\n",
    "\n",
    "# 4) compute fitted curve\n",
    "# t_fit_high = A_high * np.exp(Ea_over_kB_high / T[9:])\n",
    "# t_fit_low = A_low * np.exp(Ea_over_kB_low / T[:9])\n",
    "t_fit = A * np.exp(Ea_over_kB / T)\n",
    "\n",
    "# 5) plot data & fit\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(T, t, label=\"data\", color=\"C0\")\n",
    "# plt.plot(T[9:], t_fit_high, label=\"Arrhenius fit (high T)\", color=\"C1\")\n",
    "# plt.plot(T[:9], t_fit_low, label=\"Arrhenius fit (low T)\", color=\"C2\")\n",
    "plt.plot(T, t_fit, label=\"Overall Arrhenius fit\", color=\"C3\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Temperature (K)\")\n",
    "plt.ylabel(\"Final time (ps)\")\n",
    "plt.title(\"Arrhenius fit of final time\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_function(T):\n",
    "#     # Parameters for different temperature ranges\n",
    "#     # High temperature (>= 1400K)\n",
    "#     A_high = 4.089e-08\n",
    "#     Ea_over_kB_high = 17950.7\n",
    "    \n",
    "#     # Low temperature (< 1400K)\n",
    "#     A_low = 3.464e-06  \n",
    "#     Ea_over_kB_low = 15784.7 \n",
    "\n",
    "#     # Create boolean masks for temperature ranges\n",
    "#     high_temp_mask = T >= 1400\n",
    "#     low_temp_mask = T < 1400\n",
    "    \n",
    "#     # Initialize result array\n",
    "#     result = np.zeros_like(T, dtype=float)\n",
    "    \n",
    "#     # Calculate scaling for high temperatures\n",
    "#     if np.any(high_temp_mask):\n",
    "#         result[high_temp_mask] = np.exp(-np.log(A_high) - Ea_over_kB_high/T[high_temp_mask])\n",
    "    \n",
    "#     # Calculate scaling for low temperatures\n",
    "#     if np.any(low_temp_mask):\n",
    "#         result[low_temp_mask] = np.exp(-np.log(A_low) - Ea_over_kB_low/T[low_temp_mask])\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d271d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_function(T):\n",
    "    # Parameters for different temperature ranges\n",
    "    A = 5.088e-09\n",
    "    Ea_over_kB = 17955.5\n",
    "\n",
    "    result = np.exp(-np.log(A) - Ea_over_kB / T) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db25a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_value = scale_function(T_state)\n",
    "time_state_scaled = time_state * scale_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a942044",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time_scaled = {}\n",
    "for T in T_unique:\n",
    "    idx = np.where(T_state[:, 0] == T)[0]\n",
    "    final_time_scaled[T.item()] = time_state_scaled[idx, -1].max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911466cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(final_time_scaled.keys(), final_time_scaled.values(), label=\"data\", color=\"C0\")\n",
    "plt.xlabel(\"Temperature (K)\")\n",
    "plt.ylabel(\"Final time (ps)\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e506a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757994f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(np.arange(macro_state.shape[0]), test_size=0.4)\n",
    "train_idx.shape, val_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ef853",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_state = torch.tensor(macro_state, dtype=torch.float32)\n",
    "macro_state_partial = torch.tensor(macro_state_partial, dtype=torch.float32)\n",
    "T_state = torch.tensor(T_state, dtype=torch.int32)\n",
    "time_state = torch.tensor(time_state, dtype=torch.float32)\n",
    "time_state_scaled = torch.tensor(time_state_scaled, dtype=torch.float32)\n",
    "step_state = torch.tensor(step_state, dtype=torch.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "save_dir = f'../data/atoms_{N_atoms}'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# ========= save trainingdata =========\n",
    "# torch.save(micro_state[train_idx], f'{save_dir}/micro_state.pt')\n",
    "torch.save(macro_state[train_idx], f'{save_dir}/macro_state.pt')\n",
    "torch.save(T_state[train_idx], f'{save_dir}/T_state.pt')\n",
    "torch.save(time_state[train_idx], f'{save_dir}/time_state.pt')\n",
    "torch.save(time_state_scaled[train_idx], f'{save_dir}/time_state_scaled.pt')\n",
    "\n",
    " # ========= save partial data =========\n",
    "# save the partial macro state and idx_partial\n",
    "# torch.save(idx_partial[train_idx], f'../data/atoms_{N_atoms}/idx_partial.pt')\n",
    "torch.save(macro_state_partial[train_idx], f'../data/atoms_{N_atoms}/macro_state_partial.pt')\n",
    "\n",
    "# ========= save validation data =========\n",
    "# torch.save(micro_state[val_idx], f'{save_dir}/micro_state_val.pt')\n",
    "torch.save(macro_state[val_idx], f'{save_dir}/macro_state_val.pt')\n",
    "torch.save(T_state[val_idx], f'{save_dir}/T_state_val.pt')\n",
    "torch.save(time_state[val_idx], f'{save_dir}/time_state_val.pt')\n",
    "torch.save(time_state_scaled[val_idx], f'{save_dir}/time_state_scaled_val.pt')\n",
    "\n",
    "# torch.save(macro_state, f'{save_dir}/macro_state_short.pt')\n",
    "# torch.save(T_state, f'{save_dir}/T_state_short.pt')\n",
    "# torch.save(time_state, f'{save_dir}/time_state_short.pt')\n",
    "# torch.save(time_state_scaled, f'{save_dir}/time_state_scaled_short.pt')\n",
    "# torch.save(macro_state_partial, f'../data/atoms_{N_atoms}/macro_state_partial_short.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d85dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85fe4c9",
   "metadata": {},
   "source": [
    "### Load partial sampling data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_state_partial_sampling = []\n",
    "macro_state_sampling = []\n",
    "delta_t_state_partial_sampling = []\n",
    "step_partial_sampling = []\n",
    "\n",
    "# for output_dir in [output_dir_short, output_dir_long]:\n",
    "for output_dir in [output_dir_short]:\n",
    "    for folder in tqdm(os.listdir(output_dir)):\n",
    "        T = int(folder.split('_')[1])\n",
    "        folder_path = os.path.join(output_dir, folder)\n",
    "\n",
    "        macro_state_partial_sampling.append(np.load(os.path.join(folder_path, 'macro_vals_partial_sampling.npy')))\n",
    "        macro_state_sampling.append(np.load(os.path.join(folder_path, 'macro_vals_sampling.npy')))\n",
    "        delta_t_state_partial_sampling.append(np.load(os.path.join(folder_path, 'kmc_times_partial_sampling.npy')))\n",
    "        step_partial_sampling.append(np.load(os.path.join(folder_path, 'step_partial_sampling.npy')))\n",
    "\n",
    "macro_state_partial_sampling = np.stack(macro_state_partial_sampling, axis=0)\n",
    "delta_t_state_partial_sampling = np.stack(delta_t_state_partial_sampling, axis=0)\n",
    "macro_state_sampling = np.stack(macro_state_sampling, axis=0)\n",
    "step_partial_sampling = np.stack(step_partial_sampling, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd45781",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_partial_sampling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea6739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_state = macro_state.detach().cpu().numpy()\n",
    "macro_state_partial = macro_state_partial.detach().cpu().numpy()\n",
    "T_state = T_state.detach().cpu().numpy()\n",
    "time_state = time_state.detach().cpu().numpy()\n",
    "time_state_scaled = time_state_scaled.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac600c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 6\n",
    "delta = macro_state_partial[idx] - macro_state[idx, :-1]\n",
    "delta_partial = macro_state_partial_sampling[idx, ] - macro_state_sampling[idx, :-1]\n",
    "\n",
    "fig = plt.figure(figsize=(40, 6))\n",
    "for i in range(6):\n",
    "    axes = fig.add_subplot(1, 6, i+1)\n",
    "    \n",
    "    # # Plot distribution using histplot with normalization\n",
    "    sns.histplot(delta[:, i] / np.sqrt((time_state[idx, 1:] - time_state[idx, :-1])), \n",
    "                 ax=axes, kde=True, bins=50, alpha=0.5, color='skyblue', label='Full Sampling', stat='density')\n",
    "\n",
    "    sns.histplot(delta_partial[:, i] / np.sqrt(delta_t_state_partial_sampling[idx]), \n",
    "                 ax=axes, kde=True, bins=100, alpha=0.5, color='tab:orange', label='Partial Sampling', stat='density')\n",
    "\n",
    "    axes.set_title(f'Component {i}')\n",
    "    axes.set_xlabel('Normalized Delta')\n",
    "    axes.set_ylabel('Density')\n",
    "    # axes.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ece3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 7\n",
    "delta = macro_state_partial[idx] - macro_state[idx, :-1]\n",
    "delta_partial = macro_state_partial_sampling[idx, ] - macro_state_sampling[idx, :-1]\n",
    "\n",
    "norm = np.linalg.norm(delta, axis=1)\n",
    "norm_partial = np.linalg.norm(delta_partial, axis=1)\n",
    "\n",
    "plt.plot(norm, 'ro', markersize=1, label='Full Sampling')\n",
    "plt.plot(norm_partial, 'bo', markersize=1, label='Partial Sampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e15e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t_state_partial_sampling_scaled = delta_t_state_partial_sampling * scale_function(T_state[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87975960",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T_state[:, :-1], time_state_scaled[:, 1:] - time_state_scaled[:, :-1], 'ro', alpha=1, markersize=0.05)\n",
    "plt.plot(T_state[:, :-1], delta_t_state_partial_sampling_scaled, 'bo', alpha=0.05, markersize=0.05)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3132e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_state_partial_sampling = torch.tensor(macro_state_partial_sampling, dtype=torch.float32)\n",
    "macro_state_sampling = torch.tensor(macro_state_sampling, dtype=torch.float32)\n",
    "delta_t_state_partial_sampling_scaled = torch.tensor(delta_t_state_partial_sampling_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # ========= save partial data =========\n",
    "# save the partial macro state and idx_partial\n",
    "torch.save(macro_state_partial_sampling[train_idx], f'../data/atoms_{N_atoms}/macro_state_partial_sampling.pt')\n",
    "torch.save(macro_state_sampling[train_idx], f'../data/atoms_{N_atoms}/macro_state_sampling.pt')\n",
    "torch.save(delta_t_state_partial_sampling_scaled[train_idx], f'../data/atoms_{N_atoms}/delta_t_scaled_partial_sampling.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_state_partial_sampling.shape, macro_state_sampling.shape, delta_t_state_partial_sampling_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec97641",
   "metadata": {},
   "source": [
    "### Load partial sampling data for all temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad8670",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../data/partial_sampling_atoms_8192'\n",
    "\n",
    "# kmc_time = []\n",
    "# macro_val_partial = []\n",
    "# macro_val = []\n",
    "# T_state = []\n",
    "# step = []\n",
    "# for T in [1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 3000]:\n",
    "#     kmc_time.append(np.load(os.path.join(folder, f'kmc_times_T_{T}.npy')))\n",
    "#     macro_val_partial.append(np.load(os.path.join(folder, f'macro_vals_partial_T_{T}.npy')))\n",
    "#     macro_val.append(np.load(os.path.join(folder, f'macro_vals_T_{T}.npy')))\n",
    "#     T_state.append(T * np.ones_like(kmc_time[-1]))\n",
    "#     step.append(np.load(os.path.join(folder, f'step_T_{T}.npy')))\n",
    "\n",
    "# T_state = np.concatenate(T_state, axis=0)\n",
    "# kmc_time = np.concatenate(kmc_time, axis=0)\n",
    "# kmc_time = kmc_time * scale_function(T_state)\n",
    "# macro_val_partial = np.concatenate(macro_val_partial, axis=0)\n",
    "# macro_val = np.concatenate(macro_val, axis=0)\n",
    "\n",
    "\n",
    "# kmc_time.shape, macro_val_partial.shape, macro_val.shape, T_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T_state, kmc_time, 'ro', markersize=0.1)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181578e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_atoms = 8192\n",
    "kmc_time = torch.tensor(kmc_time, dtype=torch.float32)\n",
    "macro_val_partial = torch.tensor(macro_val_partial, dtype=torch.float32)\n",
    "macro_val = torch.tensor(macro_val, dtype=torch.float32)\n",
    "T_state = torch.tensor(T_state, dtype=torch.int32)\n",
    "\n",
    "torch.save(macro_val_partial, f'../data/atoms_{N_atoms}/macro_state_partial_sampling_tile.pt')\n",
    "torch.save(macro_val, f'../data/atoms_{N_atoms}/macro_state_sampling_tile.pt')\n",
    "torch.save(kmc_time, f'../data/atoms_{N_atoms}/delta_t_scaled_partial_sampling_tile.pt')\n",
    "torch.save(T_state, f'../data/atoms_{N_atoms}/T_state_tile.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2989f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(T_state[:, 0] == T)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f01f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2000\n",
    "kmc_time = np.load(os.path.join(folder, f'kmc_times_T_{T}.npy'))\n",
    "z1_train_partial = np.load(os.path.join(folder, f'z1_train_partial_T_{T}.npy'))\n",
    "z0_train = np.load(os.path.join(folder, f'z0_train_T_{T}.npy'))\n",
    "step = np.load(os.path.join(folder, f'step_T_{T}.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "sns.kdeplot(kmc_time, ax=axes, alpha=0.5, color='tab:orange', label='Partial Sampling')\n",
    "# sns.kdeplot(time_state[idx, 1:] - time_state[idx, -1:], ax=axes, alpha=0.5, color='tab:orange', label='Partial Sampling')\n",
    "\n",
    "axes.set_title(f'Component {i}')\n",
    "axes.set_xlabel('Normalized Delta')\n",
    "axes.set_ylabel('Density')\n",
    "# axes.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56093532",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_state[1, 1:] - time_state[1, :-1], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "(time_state[idx, 1:] - time_state[idx, -1:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec549d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 6\n",
    "idx = np.where(T_state[:, 0] == T)[0][0]\n",
    "\n",
    "fig = plt.figure(figsize=(40, 6))\n",
    "for i in range(6):\n",
    "    axes = fig.add_subplot(1, 6, i+1)\n",
    "    \n",
    "    # Plot distribution using histplot with normalization\n",
    "    sns.histplot((macro_state_partial[idx, :, i] - macro_state[idx, :-1, i]) / np.sqrt((time_state[idx, 1:] - time_state[idx, :-1])),\n",
    "                 ax=axes, kde=True, bins=50, alpha=0.5, color='skyblue', label='Full Sampling', stat='density')\n",
    "\n",
    "    sns.histplot((z1_train_partial[:, i] - z0_train[:, i]) / np.sqrt(kmc_time[:]),\n",
    "                 ax=axes, kde=True, bins=50, alpha=0.5, color='tab:orange', label='Partial Sampling', stat='density')\n",
    "\n",
    "    axes.set_title(f'Component {i}')\n",
    "    axes.set_xlabel('Normalized Delta')\n",
    "    axes.set_ylabel('Density')\n",
    "    # axes.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea3444",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 6\n",
    "idx = np.where(T_state[:, 0] == T)[0][0]\n",
    "\n",
    "fig = plt.figure(figsize=(40, 6))\n",
    "for i in range(6):\n",
    "    axes = fig.add_subplot(1, 6, i+1)\n",
    "    \n",
    "    # Plot distribution using histplot with normalization\n",
    "    sns.histplot(macro_state[idx, :-1, i],\n",
    "                 ax=axes, kde=True, bins=50, alpha=0.5, color='skyblue', label='Full Sampling', stat='density')\n",
    "\n",
    "    # sns.histplot(z0_train[:, i],\n",
    "    #              ax=axes, kde=True, bins=50, alpha=0.5, color='tab:orange', label='Partial Sampling', stat='density')\n",
    "\n",
    "    axes.set_title(f'Component {i}')\n",
    "    axes.set_xlabel('Normalized Delta')\n",
    "    axes.set_ylabel('Density')\n",
    "    # axes.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4729634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2000\n",
    "fig = plt.figure(figsize=(40, 6))\n",
    "for i in range(6):\n",
    "    axes = fig.add_subplot(1, 6, i+1)\n",
    "    for j in [6]:\n",
    "        axes.plot(time_state[j], macro_state[j, :, i])\n",
    "    axes.set_xlabel('Step')\n",
    "    axes.set_ylabel(f'Delta_{i}')\n",
    "    axes.set_ylim(-3.5, 3.5)\n",
    "plt.title(f'T = {T} K')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464cd32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(macro_state[idx], axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
